{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpi4py in c:\\users\\shaky\\anaconda3\\envs\\gameofvenv\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numba in c:\\users\\shaky\\anaconda3\\envs\\gameofvenv\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\shaky\\anaconda3\\envs\\gameofvenv\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\shaky\\anaconda3\\envs\\gameofvenv\\lib\\site-packages (from numba) (0.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mpi4py numba numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPI test successful\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "print(\"MPI test successful\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 CUDA devices\n",
      "id 0    b'NVIDIA GeForce RTX 4060 Laptop GPU'                              [SUPPORTED]\n",
      "                      Compute Capability: 8.9\n",
      "                           PCI Device ID: 0\n",
      "                              PCI Bus ID: 1\n",
      "                                    UUID: GPU-1ab98dcd-76e5-ee1b-ec1c-c1efb90cdc10\n",
      "                                Watchdog: Enabled\n",
      "                            Compute Mode: WDDM\n",
      "             FP32/FP64 Performance Ratio: 64\n",
      "Summary:\n",
      "\t1/1 devices are supported\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "\n",
    "print(cuda.detect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def game_of_life_kernel(current_grid, next_grid, rows, cols):\n",
    "    # Get thread's absolute position within the grid\n",
    "    x, y = cuda.grid(2)\n",
    "\n",
    "    if x >= rows or y >= cols:\n",
    "        return  # Out of bounds\n",
    "\n",
    "    # Count live neighbors\n",
    "    live_neighbors = 0\n",
    "    for i in range(-1, 2):\n",
    "        for j in range(-1, 2):\n",
    "            if i == 0 and j == 0:\n",
    "                continue\n",
    "            neighbor_x = (x + i + rows) % rows\n",
    "            neighbor_y = (y + j + cols) % cols\n",
    "            live_neighbors += current_grid[neighbor_x, neighbor_y]\n",
    "\n",
    "    # Apply rules of Game of Life\n",
    "    if current_grid[x, y] == 1:\n",
    "        if live_neighbors < 2 or live_neighbors > 3:\n",
    "            next_grid[x, y] = 0\n",
    "        else:\n",
    "            next_grid[x, y] = 1\n",
    "    else:\n",
    "        if live_neighbors == 3:\n",
    "            next_grid[x, y] = 1\n",
    "        else:\n",
    "            next_grid[x, y] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mpi_game_of_life(grid_size, num_generations, proc_grid_size):\n",
    "    comm = MPI.COMM_WORLD\n",
    "    rank = comm.Get_rank()\n",
    "    size = comm.Get_size()\n",
    "\n",
    "    rows, cols = grid_size\n",
    "\n",
    "    # Each process will work on a subgrid\n",
    "    local_rows = rows // proc_grid_size\n",
    "    local_grid = np.random.randint(2, size=(local_rows, cols))\n",
    "\n",
    "    # Allocate space for the next grid state\n",
    "    next_grid = np.zeros_like(local_grid)\n",
    "\n",
    "    # Setup GPU grid and thread dimensions\n",
    "    threads_per_block = (16, 16)\n",
    "    blocks_per_grid_x = (local_rows + threads_per_block[0] - 1) // threads_per_block[0]\n",
    "    blocks_per_grid_y = (cols + threads_per_block[1] - 1) // threads_per_block[1]\n",
    "    blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n",
    "\n",
    "    for _ in range(num_generations):\n",
    "        # Copy data to GPU\n",
    "        d_local_grid = cuda.to_device(local_grid)\n",
    "        d_next_grid = cuda.to_device(next_grid)\n",
    "\n",
    "        # Call kernel\n",
    "        game_of_life_kernel[blocks_per_grid, threads_per_block](d_local_grid, d_next_grid, local_rows, cols)\n",
    "\n",
    "        # Copy result back to host\n",
    "        d_next_grid.copy_to_host(next_grid)\n",
    "\n",
    "        # Exchange rows between neighboring processes\n",
    "        if rank > 0:\n",
    "            comm.Sendrecv(local_grid[0, :], dest=rank - 1, sendtag=11,\n",
    "                          recvbuf=local_grid[-1, :], source=rank - 1, recvtag=11)\n",
    "        if rank < size - 1:\n",
    "            comm.Sendrecv(local_grid[-1, :], dest=rank + 1, sendtag=12,\n",
    "                          recvbuf=local_grid[0, :], source=rank + 1, recvtag=12)\n",
    "\n",
    "        # Update local grid with next generation\n",
    "        local_grid = next_grid.copy()\n",
    "\n",
    "    # Gather final grid at root process (rank 0)\n",
    "    full_grid = None\n",
    "    if rank == 0:\n",
    "        full_grid = np.zeros((rows, cols))\n",
    "    comm.Gather(local_grid, full_grid, root=0)\n",
    "\n",
    "    return full_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shaky\\anaconda3\\envs\\gameofvenv\\Lib\\site-packages\\numba\\cuda\\dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
      "  warn(NumbaPerformanceWarning(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final grid after 100 generations:\n",
      "[[0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 4.94065646e-324\n",
      "  2.12199579e-314 0.00000000e+000]\n",
      " ...\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 0.00000000e+000 0.00000000e+000 ... 0.00000000e+000\n",
      "  0.00000000e+000 0.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    grid_size = (128, 128)  # Example grid size\n",
    "    num_generations = 100   # Example number of generations\n",
    "    proc_grid_size = MPI.COMM_WORLD.Get_size()  # Number of processes\n",
    "    final_grid = mpi_game_of_life(grid_size, num_generations, proc_grid_size)\n",
    "\n",
    "    if MPI.COMM_WORLD.Get_rank() == 0:\n",
    "        print(\"Final grid after {} generations:\".format(num_generations))\n",
    "        print(final_grid)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gameofvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
